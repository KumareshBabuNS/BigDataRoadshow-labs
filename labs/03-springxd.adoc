== Spring XD overview lab

This lab will go through a general overview using Spring XD. +
For lab and demo purposes, we'll be using a single node system, although Spring XD will scale horizontally as needed.

Requirements

- http://projects.spring.io/spring-xd/[Spring XD] v1.1.0 + installed 

=== Starting Spring XD

Start a single node instance of Spring XD, typing on a terminal:

[source,bash]
----
$ xd-singlenode

 _____                           __   _______
/  ___|          (-)             \ \ / /  _  \
\ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |
 `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |
/\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /
\____/| .__/|_|  |_|_| |_|\__, | \/   \/___/
      | |                  __/ |
      |_|                 |___/
1.1.0.RELEASE                    eXtreme Data


Started : SingleNodeApplication

(...)

1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.ContainerListener - Container arrived: Container{name='9b736207-17df-4ba8-bfb7-8f68a14ab466', attributes={ip=192.168.1.2, host=Fredericos-Air, groups=, pid=9011, id=9b736207-17df-4ba8-bfb7-8f68a14ab466}}
1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.ContainerListener - Scheduling deployments to new container(s) in 15000 ms
----
Wait for the server startup to be complete, it will take a few seconds. +
Once the server is up and running, let's connect to it from the XD Shell:

[source,bash]
----
$ xd-shell

 _____                           __   _______
/  ___|          (-)             \ \ / /  _  \
\ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |
 `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |
/\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /
\____/| .__/|_|  |_|_| |_|\__, | \/   \/___/
      | |                  __/ |
      |_|                 |___/
eXtreme Data
1.1.0.RELEASE | Admin Server Target: http://localhost:9393
Welcome to the Spring XD shell. For assistance hit TAB or type "help".
xd:>
----

As the server is running on the same machine, the XD Shell automatically recognized it and connected. +
We're ready to create our first streams.

First, let's check no stream is currently running:

[source,bash]
----
xd:> stream list
  Stream Name  Stream Definition  Status
  -----------  -----------------  ------
----
The list should be empty, meaning no streams currently exist.

=== Creating a few simple streams

Let's start creating a few very simple data streams that will simply read data from different sources and directly output to select destinations. 

* Reading the system's time and outputing to the log:

On the XD shell window, type:

[source,bash]
----
xd:> stream create stream1 --definition "time | log" --deploy
Created and deployed new stream 'stream1'
----
Check the logs on the window where you started __xd-singlenode__. It should be outputing time ticks. +
Now the _stream list_ command should also identify the stream we created and we should be able to destroy it when desired:

[source,bash]
----
xd:>stream list
  Stream Name  Stream Definition  Status
  -----------  -----------------  --------
  stream1      time|log           deployed

xd:>stream destroy stream1
Destroyed stream 'stream1'

----
 
 Now let's change it a little in order to output to a file instead.
 
* Reading the system's time and outputing to a file:
 
[source,bash]
----
xd:>stream create streamTimeFile --definition "time | file --name=mystream --dir=/tmp" --deploy
Created and deployed new stream 'streamTimeFile'
----

Check the log file on a terminal window and see the time is now being output there: +
 +
[source,bash]
----
$ tail -f /tmp/mystream.out
2015-03-13 23:38:19
2015-03-13 23:38:20

----

* Listening HTTP port and outputing to a file +

As the next step on this exercise, let's change the _source_ to be something more useful than "time"  
If we specify _http_, XD will automatically start listening to HTTP connections on a port, where we can submit our data to:
 +
[source,bash]
----
xd:>stream create httptofile --definition "http --port=9020 | file --name=fromhttp --dir=/tmp" --deploy
Created and deployed new stream 'httptofile'
----

Now we'll use XD-shell itself to send a JSON object to that HTTP listener:
 +
[source,bash]
----
xd:> http post --target 'http://localhost:9020' --data '{Values : [{"X":0,"Y":1,"Z":0,"key":0},{"X":1,"Y":0,"Z":0,"key":1}]}'

> POST (text/plain;Charset=UTF-8) http://localhost:9020 {Values : [{"X":0,"Y":1,"Z":0,"key":0},{"X":1,"Y":0,"Z":0,"key":1}]}
> 200 OK
----

As expected, that data should be now in the /tmp/fromhttp.out file, as specified:
 +
[source,bash]
----
$ cat /tmp/fromhttp.out 
{Values : [{"X":0,"Y":1,"Z":0,"key":0},{"X":1,"Y":0,"Z":0,"key":1}]}
----
 
* Extracting JSON data +
 
As a next step, we'll see how XD can be used to easily apply built-in transformations, like extracting specific fields from JSON requests on a data stream. +
Deploy the following stream:
 +
[source,bash]
----
xd:>stream create transform --definition "http --port=9030 | splitter --expression=#jsonPath(payload,'$.Values') | file --name=transform --dir=/tmp" --deploy
Created and deployed new stream 'transform'
----

Let's send the exact same data to this new stream:
 +
[source,bash]
----
xd:>http post --target 'http://localhost:9030' --data '{Values : [{"X":0,"Y":1,"Z":0,"key":0},{"X":1,"Y":0,"Z":0,"key":1}]}'
> POST (text/plain;Charset=UTF-8) http://localhost:9030 {Values : [{"X":0,"Y":1,"Z":0,"key":0},{"X":1,"Y":0,"Z":0,"key":1}]}
> 200 OK
----

The result, as output on the file specified, is the each value extracted as expected. 
 +
[source,bash]
----
$ cat /tmp/transform.out 
{X=0, Y=1, Z=0, key=0}
{X=1, Y=0, Z=0, key=1}
----
Each value of our JSON object array was extracted as a separate line by the _splitter_ module.
 
Next, we'll add an additional filter to the same definition, extracting only the lines where _Y_ has the value _0_
 +
[source,bash]
----
xd:>stream create transform2 --definition "http --port=9040 | splitter --expression=#jsonPath(payload,'$.Values') | filter --expression=#jsonPath(payload,'$.Y').equals(0) | file --name=transform2 --dir=/tmp" --deploy
Created and deployed new stream 'transform2'
----
 
Sending the exact same data as input, we should only see as output the line with the value specified on the filtering module:
 +
[source,bash]
----
 xd:>http post --target 'http://localhost:9040' --data '{Values : [{"X":0,"Y":1,"Z":0,"key":0},{"X":1,"Y":0,"Z":0,"key":1}]}'
> POST (text/plain;Charset=UTF-8) http://localhost:9040 {Values : [{"X":0,"Y":1,"Z":0,"key":0},{"X":1,"Y":0,"Z":0,"key":1}]}
> 200 OK
----
Checking the output..
[source,bash]
----
$ cat /tmp/transform2.out 
{X=1, Y=0, Z=0, key=1}
----


* Listening HTTP port and outputing to HDFS

xd:>hadoop config fs --namenode hdfs://localhost:8020

xd:>hadoop config fs --namenode hdfs://localhost:8020

xd:> stream create --name myhdfsstream1 --definition "http | hdfs" --deploy

xd:>hadoop fs ls /xd/myhdfsstream1
Found 1 items
-rw-r--r--   3 jvalkealahti supergroup          0 2013-12-18 18:10 /xd/myhdfsstream1/myhdfsstream1-0.txt.tmp

+
+
+
start locator --name=locator1
+
start server --name=server1 --J=-Dgemfire.start-dev-rest-api=true --J=-Dgemfire.http-service-port=8080
+
create region --name=/Stocks --type=REPLICATE
+


+
+
+
+


=== Applying a simple Data Filtering / Transformation

For this example, we'll use Yahoo Query Language (YQL) REST interface to query quotes from our favorite stock.

Using our browser, open https://query.yahooapis.com/v1/public/yql?q=select%20*%20from%20yahoo.finance.quote%20where%20symbol%20in%20(%22EMC%22)&env=store%3A%2F%2Fdatatables.org%2Falltableswithkeys&format=json

{"query":
     {"count":1,"created":"2015-03-16T07:05:57Z",
      "lang":"en-US",
      "results":{
          "quote":{
              "symbol":"EMC",
              "AverageDailyVolume":
              "15112500",
              "Change":"-0.17",
              "DaysLow":"25.49",
              "DaysHigh":"26.08",
              "YearLow":"24.92",
              "YearHigh":"30.92",
              "MarketCapitalization":"51.69B",
              "LastTradePriceOnly":"26.00",
              "DaysRange":"25.49 - 26.08",
              "Name":"EMC Corporation Common Stock",
              "Symbol":"EMC",
              "Volume":"18974738",
              "StockExchange":"NYQ"
            }
         }
       }
  }

Note the response in JSON format. We can query the same data at each 3 seconds and output the result to XD's log file creating the stream:

[source,shell]
----
xd:> stream create stream1 --definition "trigger --fixedDelay=10 | http-client --url='''https://query.yahooapis.com/v1/public/yql?q=select * from yahoo.finance.quote where symbol in (\"MSFT\")&format=json&env=store://datatables.org/alltableswithkeys''' --httpMethod=GET | log" --deploy 
----

However, we're only interested on the *results* object of the json response, more specifically the *results.quote* object.

So let's apply add quick filtering to only have that part of the result:  +splitter --expression=#jsonPath(payload,'$.query.results.quote')+ 

[source,shell]
----
xd:> stream create stream1 --definition "trigger --fixedDelay=10 | http-client --url='''https://query.yahooapis.com/v1/public/yql?q=select * from yahoo.finance.quote where symbol in (\"MSFT\")&format=json&env=store://datatables.org/alltableswithkeys''' --httpMethod=GET | splitter --expression=#jsonPath(payload,'$.query.results.quote') | log" --deploy 
----

You should see in the log only the stock quote data, eliminating all the header we were not interested on.

=== Enriching with a simple Groovy script

Create a file called __transform.groovy__  as following:

[source,groovy]
----
payload.put("timestamp", headers.get('timestamp'))
return payload
----

Those simple two lines will be responsible for adding the timestamp of the message to the JSON object containing the quote, as we'll use that to store in our in-memory grid.
To verify the result, use the stream:

[source,shell]
----
xd:> stream create stream1 --definition "trigger --fixedDelay=10 | http-client --url='''https://query.yahooapis.com/v1/public/yql?q=select * from yahoo.finance.quote where symbol in (\"MSFT\")&format=json&env=store://datatables.org/alltableswithkeys''' --httpMethod=GET | splitter --expression=#jsonPath(payload,'$.query.results.quote') |  transform --script='file:[path_to_your_file]/transform.groovy' | log" --deploy 
----

=== Sinking the data into GemFire

Start a GemFire server:

[source,shell]
----
$ gfsh

gfsh$ 

BLA BLA BLA
----

Create a region called Stocks to hold the information Spring XD will be sinking there:

[source,shell]
----
gfsh $ create region 

BLA BLA BLA
----


Create the Spring XD stream that outputs the data already filtered and enriched into GemFire:

[source,shell]
----
stream create stream1 --definition "trigger --fixedDelay=3 | http-client --url='''https://query.yahooapis.com/v1/public/yql?q=select * from yahoo.finance.quote where symbol in (\"MSFT\")&format=json&env=store://datatables.org/alltableswithkeys''' --httpMethod=GET | splitter --expression=#jsonPath(payload,'$.query.results.quote') | transform --script='file:/Users/fmelo/FinanceStream/transform.groovy'| gemfire-json-server --useLocator=true --host=localhost --port=10334 --regionName=Stocks --keyExpression=payload.getField('timestamp')" --deploy
----


=== Creating a second stream to read data from GemFire 

[source,shell]
----
stream create stream2 --definition "gemfire --regionName=Stocks --useLocator=true --host=localhost --port=10334 | shell --command='Rscript /Users/fmelo/FinanceStream/test.R' | log " --deploy
----




Troubleshoot any issues until you have your first custom bosh release deployment!! (there are some corrections to be done!) The troubleshooting part is very important!! That's how you learn!!

Hints: 

- The failing canary will be kept by bosh for troubleshooting purposes
- When testing, subsequent deployments should be done using __bosh deploy --recreate__ , otherwise new additional VMs will be created (canary won't be updated unless __--recreate__ is specified).
- Check logs and try to understand what's going on. You can try to run the commands yourself once logged into the VM to understand what's wrong.
- Dr Nick created a project called https://github.com/drnic/bosh-solo[BOSH-Solo] which helps testing BOSH releases. You might want to give it a try! (not mandatory)

Good luck!! Next challenge is adding a Service Broker capable of provisioning PostgreSQL instances to the release you just created :)

If you'd like to check the solution for this lab, clone this repo: https://github.com/Pivotal-Field-Engineering/postgres-bosh-release[postgres-bosh-release]
