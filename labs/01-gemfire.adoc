
= Gemfire Lab
The purpose of this lab is to get a basic understanding of how a Gemfire cluster works and how it can be used.

== Exploring gfsh
gfsh (Gemfire shell) is a interactive command line interface that allows you to, manage, moniter and administrate Gemfire processes +
Through out this lab gfsh will be used to start and stop processes and also to initiate other commands to the cluster
To start gfsh execute the following steps: +
1. Right click on the desktop and select _Open In Terminal_ +
2. In the terminal type "'gfsh'" +

The following interface will appear:
[source]
----
    _________________________     __
   / _____/ ______/ ______/ /____/ /
  / /  __/ /___  /_____  / _____  / 
 / /__/ / ____/  _____/ / /    / /  
/______/_/      /______/_/    /_/    v8.1.0

Monitor and Manage GemFire
gfsh>
----

gfsh is interactive and contains auto completes to assist users. This functionality can be triggered by pressing the tab key. Press tab now to list all the commands gfsh can perform.

== Starting The First Member of the Cluster
The locator is a Pivotal GemFire process that tells new, connecting members/clients where running members are located and provides load balancing for server use. +
This locator will be the first member in the cluster and will act as the membership coordinator as well as the management node. +
Copy and paste the following command into gfsh: +
[source,bash]
----
start locator --name=locatorA --enable-cluster-configuration=false --port=10334 --log-level=config --J=-Xms64m --J=-Xmx64m --J=-Dgemfire.http-service-port=7575
----

The command will produce an output similar to this: +
[source,bash]
----
_gfsh>start locator --name=locatorA --enable-cluster-configuration=false --port=10334 --log-level=config --J=-Xms64m --J=-Xmx64m --J=-Dgemfire.http-service-port=7575
Starting a GemFire Locator in /home/gemfire/locatorA...
Locator in /home/gemfire/locatorA on 192.168.75.9[10334] as locatorA is currently online.
Process ID: 67956
Uptime: 16 seconds
GemFire Version: 8.1.0
Java Version: 1.7.0_71
Log File: /home/gemfire/locatorA/locatorA.log
JVM Arguments: -Dgemfire.enable-cluster-configuration=false -Dgemfire.load-cluster-configuration-from-dir=false -Dgemfire.log-level=config -Xms64m -Xmx64m -Dgemfire.http-service-port=7575 -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806
Class-Path: /home/gemfire/gemfire/Pivotal_GemFire/lib/gemfire.jar:/home/gemfire/gemfire/Pivotal_GemFire/lib/locator-dependencies.jar_

Successfully connected to: [host=192.168.75.9, port=1099]
----
Congratulations, you now have the beginning of a Gemfire cluster.

== Log Into Pulse
GemFire Pulse is a Web Application that provides a graphical dashboard for monitoring vital, real-time health and performance of GemFire clusters, members, and regions. +
With the first locator started, Pulse is now available. +
To start up Pulse, open a browser and enter this URL in the address bar: +
http://localhost:7575/pulse/Login.html +

Log In with the following credentials: +
username: *admin* +
password: *admin* +
Once logged in click on green server box Icon in the Cluster View to see the Gemfire processes running on the server. +
For the lab all processes will be on this machine.
image::/01-gemfire/images/pulse-cluster-view.png


== Start another Locator
This locator will join with the first giving us fail over for Locator functionality. +
Return to the gfsh session and enter the following command: +
[source,bash]
----
start locator --name=locatorB --enable-cluster-configuration=false --locators=127.0.0.1[10334],127.0.0.1[10335] --port=10335 --log-level=config --J=-Xms64m --J=-Xmx64m --J=-Dgemfire.http-service-port=7576
----
The resulting output should look like the following: +
[source]
----
Locator in /home/gemfire/locatorB on 192.168.75.9[10335] as locatorB is currently online.
Process ID: 72956
Uptime: 4 seconds
GemFire Version: 8.1.0
Java Version: 1.7.0_71
Log File: /home/gemfire/locatorB/locatorB.log
JVM Arguments: -Dgemfire.locators=127.0.0.1[10334],127.0.0.1[10335] -Dgemfire.enable-cluster-configuration=false -Dgemfire.load-cluster-configuration-from-dir=false -Dgemfire.log-level=config -Xms64m -Xmx64m -Dgemfire.http-service-port=7576 -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806
Class-Path: /home/gemfire/gemfire/Pivotal_GemFire/lib/gemfire.jar:/home/gemfire/gemfire/Pivotal_GemFire/lib/locator-dependencies.jar
----

Pulse will now show two locator processes. Also in the panel across the top the Total Heap, Members and Locators counts will have increased.

== Add Server A
A GemFire server is a Pivotal GemFire process that runs as a long-lived, configurable member of a distributed system. +
The server is what contains the Regions which in turn contains the data. Servers can also bring the compute to the data, similar to stored Procedures, by deploying java logic into them. +

To start a server process copy the following command into gfsh: +
[source,bash]
----
start server --name=serverA --use-cluster-configuration=false --server-port=0 --locators=127.0.0.1[10334],127.0.0.1[10335] --J=-Dgemfire.http-service-port=7577 --J=-Dgemfire.start-dev-rest-api=true --J=-Xms128m --J=-Xmx128m
----

The output will look similar to this: +

[source]
----
_Server in /home/gemfire/serverA on 192.168.75.9[33971] as serverA is currently online.
Process ID: 88547
Uptime: 9 seconds
GemFire Version: 8.1.0
Java Version: 1.7.0_71
Log File: /home/gemfire/serverA/serverA.log
JVM Arguments: -Dgemfire.locators=127.0.0.1[10334],127.0.0.1[10335] -Dgemfire.use-cluster-configuration=false -Dgemfire.http-service-port=7577 -Dgemfire.start-dev-rest-api=true -Xms128m -Xmx128m -XX:OnOutOfMemoryError=kill -KILL %p -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806
Class-Path: /home/gemfire/gemfire/Pivotal_GemFire/lib/gemfire.jar:/home/gemfire/gemfire/Pivotal_GemFire/lib/server-dependencies.jar_
----

Pulse will now also show the new member as well as the increase in memory capacity the addition of this process provided. +

The members can also be view in gfsh by typing this command (remember by pressing tab as you type, autocomplete will help):
[source,bash]
----
list members
----

The output will look something like this:
[source]
----
gfsh>list members +
  Name   | Id +
-------- | ----------------------------------------------
locatorB | 192.168.75.9(locatorB:72956:locator)<v1>:20048
serverA  | 192.168.75.9(serverA:88547)<v2>:24402
locatorA | 192.168.75.9(locatorA:72292:locator)<v0>:58229
----

== Add the Rest of the Members
To add the rest of the members in the grid, enter each line into gfsh. Wait for the command to complete and the process to start before entering the next command.
[source,bash]
----
start server --name=serverB --use-cluster-configuration=false --server-port=0 --locators=127.0.0.1[10334],127.0.0.1[10335] --J=-Dgemfire.http-service-port=7578 --J=-Dgemfire.start-dev-rest-api=true --J=-Xms128m --J=-Xmx128m
start server --name=serverC --use-cluster-configuration=false --server-port=0 --locators=127.0.0.1[10334],127.0.0.1[10335] --J=-Dgemfire.http-service-port=7579 --J=-Dgemfire.start-dev-rest-api=true --J=-Xms128m --J=-Xmx128m
start server --name=serverD --use-cluster-configuration=false --server-port=0 --locators=127.0.0.1[10334],127.0.0.1[10335] --J=-Dgemfire.http-service-port=7580 --J=-Dgemfire.start-dev-rest-api=true --J=-Xms128m --J=-Xmx128m
----
At the end of this process a cluster with six members should be visible in gfsh and pulse.
[source,bash]
----
gfsh>list members
  Name   | Id
-------- | ----------------------------------------------
serverB  | 192.168.75.9(serverB:90339)<v3>:5220
serverD  | 192.168.75.9(serverD:90869)<v5>:14761
locatorB | 192.168.75.9(locatorB:72956:locator)<v1>:20048
serverA  | 192.168.75.9(serverA:88547)<v2>:24402
serverC  | 192.168.75.9(serverC:90642)<v4>:39304
locatorA | 192.168.75.9(locatorA:72292:locator)<v0>:58229
----
image::/01-gemfire/images/pulse-full-cluster-view.png

== Adding Regions
The region is the core building block of the Pivotal GemFire distributed system. All cached data is organized into data regions and you do all of your data puts, gets, and querying activities against them. +
Regions behave like HashMaps in that key/value pairs are put into them. +
There are two Region types: +
1. Replicated - when a client sends data to a server and puts a key/value into this type of Region, that key/value is copied to all servers that have that region. +
2. Partitioned - when a client sends data into this type of Region, a hashing policy is performed on the key and using this one server is selected to hold that key/value. In most cases redundant copies are made. +
Regions are usually created using XML that is passed into the server on the start server command. +
This is an example: +
[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<cache
    xmlns="http://schema.pivotal.io/gemfire/cache"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://schema.pivotal.io/gemfire/cache http://schema.pivotal.io/gemfire/cache/cache-8.1.xsd"
    version="8.1">
  <cache-server port="${PORT}" max-connections="${MAXCNXS}"/>
  <region name="root">
    <region-attributes refid="REPLICATE"/>
  </region>
</cache>
----
In this lab, to get a better feel for the process, Regions will be created on the fly using gfsh. +

Add the following command in gfsh:
[source]
----
create region --name=product --type=REPLICATE
----
It will procude an output like this following:
[source]
----
gfsh>create region --name=product --type=REPLICATE
Member  | Status
------- | --------------------------------------
serverC | Region "/product" created on "serverC"
serverB | Region "/product" created on "serverB"
serverA | Region "/product" created on "serverA"
serverD | Region "/product" created on "serverD"
----
In the top banner of Pulse the Regions count will also show 1. +
By clicking the Data tab in Pulse the viewer will show one large region. +
image::/01-gemfire/images/pulse-data-first-region.png
By click on this grey box, Pulse will show how the data is distributed across the servers. This is a Replicated region, so it will be in all of them. +
image::/01-gemfire/images/pulse-data-first-region-members.png

Create another replicated Region:
[source,bash]
----
create region --name=customer --type=REPLICATE
----
Now create a Partitioned Region.
[source,bash]
----
create region --name=transaction --type=PARTITION --redundant-copies=1
----
When using the tab key, the options for Partitioned regions may have come up.
[source]
----
PARTITION                                 
PARTITION_REDUNDANT                       
PARTITION_PERSISTENT                      
PARTITION_REDUNDANT_PERSISTENT            
PARTITION_OVERFLOW                        
PARTITION_REDUNDANT_OVERFLOW              
PARTITION_PERSISTENT_OVERFLOW             
PARTITION_REDUNDANT_PERSISTENT_OVERFLOW   
PARTITION_HEAP_LRU                        
PARTITION_REDUNDANT_HEAP_LRU              
PARTITION_PROXY                           
PARTITION_PROXY_REDUNDANT
---
Gemfire has a lot of configuration options to cover a wide range of use cases. More than be covered during this lab. +
http://gemfire.docs.pivotal.io/latest/userguide/index.html#developing/partitioned_regions/chapter_overview.html



